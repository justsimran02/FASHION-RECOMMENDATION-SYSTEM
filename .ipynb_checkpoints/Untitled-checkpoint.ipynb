{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653d9130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd51adc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (4.6.3)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "Successfully installed typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U typing-extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d67278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep typing-extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987db486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f201488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'gender', 'masterCategory', 'subCategory', 'articleType',\n",
      "       'baseColour', 'season', 'year', 'usage', 'productDisplayName'],\n",
      "      dtype='object')\n",
      "Column 'actual_column_name' does not exist in the DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samee\\AppData\\Local\\Temp\\ipykernel_20304\\548406967.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file_path, error_bad_lines=False)\n",
      "Skipping line 6044: expected 10 fields, saw 11\n",
      "Skipping line 6569: expected 10 fields, saw 11\n",
      "Skipping line 7399: expected 10 fields, saw 11\n",
      "Skipping line 7939: expected 10 fields, saw 11\n",
      "Skipping line 9026: expected 10 fields, saw 11\n",
      "Skipping line 10264: expected 10 fields, saw 11\n",
      "Skipping line 10427: expected 10 fields, saw 11\n",
      "Skipping line 10905: expected 10 fields, saw 11\n",
      "Skipping line 11373: expected 10 fields, saw 11\n",
      "Skipping line 11945: expected 10 fields, saw 11\n",
      "Skipping line 14112: expected 10 fields, saw 11\n",
      "Skipping line 14532: expected 10 fields, saw 11\n",
      "Skipping line 15076: expected 10 fields, saw 12\n",
      "Skipping line 29906: expected 10 fields, saw 11\n",
      "Skipping line 31625: expected 10 fields, saw 11\n",
      "Skipping line 33020: expected 10 fields, saw 11\n",
      "Skipping line 35748: expected 10 fields, saw 11\n",
      "Skipping line 35962: expected 10 fields, saw 11\n",
      "Skipping line 37770: expected 10 fields, saw 11\n",
      "Skipping line 38105: expected 10 fields, saw 11\n",
      "Skipping line 38275: expected 10 fields, saw 11\n",
      "Skipping line 38404: expected 10 fields, saw 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File path to your CSV dataset\n",
    "file_path = \"C:\\\\Users\\\\samee\\\\Downloads\\\\styles.csv\\\\styles.csv\"\n",
    "\n",
    "# Load CSV file into a Pandas DataFrame with error handling\n",
    "try:\n",
    "    df = pd.read_csv(file_path, error_bad_lines=False)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"ParserError: {e}\")\n",
    "\n",
    "# Check all column names in your DataFrame\n",
    "print(df.columns)\n",
    "\n",
    "# Example: Replace 'actual_column_name' with a valid column name from df.columns\n",
    "actual_column_name = 'actual_column_name'  # Replace with an actual column name from df.columns\n",
    "\n",
    "# Verify if actual_column_name exists in df.columns\n",
    "if actual_column_name in df.columns:\n",
    "    # Plotting a histogram of the selected numerical column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df[actual_column_name], bins=20, edgecolor='black')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of {actual_column_name}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{actual_column_name}' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4f3853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot Recommendation: Casual Shoes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samee\\AppData\\Local\\Temp\\ipykernel_20304\\2503206391.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file_path, error_bad_lines=False)\n",
      "Skipping line 6044: expected 10 fields, saw 11\n",
      "Skipping line 6569: expected 10 fields, saw 11\n",
      "Skipping line 7399: expected 10 fields, saw 11\n",
      "Skipping line 7939: expected 10 fields, saw 11\n",
      "Skipping line 9026: expected 10 fields, saw 11\n",
      "Skipping line 10264: expected 10 fields, saw 11\n",
      "Skipping line 10427: expected 10 fields, saw 11\n",
      "Skipping line 10905: expected 10 fields, saw 11\n",
      "Skipping line 11373: expected 10 fields, saw 11\n",
      "Skipping line 11945: expected 10 fields, saw 11\n",
      "Skipping line 14112: expected 10 fields, saw 11\n",
      "Skipping line 14532: expected 10 fields, saw 11\n",
      "Skipping line 15076: expected 10 fields, saw 12\n",
      "Skipping line 29906: expected 10 fields, saw 11\n",
      "Skipping line 31625: expected 10 fields, saw 11\n",
      "Skipping line 33020: expected 10 fields, saw 11\n",
      "Skipping line 35748: expected 10 fields, saw 11\n",
      "Skipping line 35962: expected 10 fields, saw 11\n",
      "Skipping line 37770: expected 10 fields, saw 11\n",
      "Skipping line 38105: expected 10 fields, saw 11\n",
      "Skipping line 38275: expected 10 fields, saw 11\n",
      "Skipping line 38404: expected 10 fields, saw 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your fashion dataset from CSV\n",
    "file_path = \"C:\\\\Users\\\\samee\\\\Downloads\\\\styles.csv\\\\styles.csv\"\n",
    "df = pd.read_csv(file_path, error_bad_lines=False)\n",
    "\n",
    "# Adjust column selection based on your dataset structure\n",
    "# Assuming your dataset includes columns like 'articleType', 'productDisplayName', etc.\n",
    "# Replace with actual column names from your dataset\n",
    "if 'articleType' in df.columns:\n",
    "    data = df['articleType'].astype(str).tolist()\n",
    "elif 'productDisplayName' in df.columns:\n",
    "    data = df['productDisplayName'].astype(str).tolist()\n",
    "else:\n",
    "    raise KeyError(\"None of the expected columns ('articleType', 'productDisplayName') found in the dataset.\")\n",
    "\n",
    "# Example NLP intent recognition and recommendation function\n",
    "def process_query(query, data):\n",
    "    # Tokenize and vectorize user query and product names\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    data_vectors = vectorizer.fit_transform(data)\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, data_vectors)\n",
    "\n",
    "    # Retrieve top recommendation\n",
    "    top_idx = similarities.argsort()[0][-1]\n",
    "    return data[top_idx]\n",
    "\n",
    "# Example usage:\n",
    "user_query = \"Looking for stylish Adidas shoes.\"\n",
    "recommendation = process_query(user_query, data)\n",
    "print(\"Chatbot Recommendation:\", recommendation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4198623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\samee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\samee\\AppData\\Local\\Temp\\ipykernel_20304\\2878072381.py:16: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "C:\\Users\\samee\\AppData\\Local\\Temp\\ipykernel_20304\\2878072381.py:16: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 6044: expected 10 fields, saw 11\n",
      "Skipping line 6569: expected 10 fields, saw 11\n",
      "Skipping line 7399: expected 10 fields, saw 11\n",
      "Skipping line 7939: expected 10 fields, saw 11\n",
      "Skipping line 9026: expected 10 fields, saw 11\n",
      "Skipping line 10264: expected 10 fields, saw 11\n",
      "Skipping line 10427: expected 10 fields, saw 11\n",
      "Skipping line 10905: expected 10 fields, saw 11\n",
      "Skipping line 11373: expected 10 fields, saw 11\n",
      "Skipping line 11945: expected 10 fields, saw 11\n",
      "Skipping line 14112: expected 10 fields, saw 11\n",
      "Skipping line 14532: expected 10 fields, saw 11\n",
      "Skipping line 15076: expected 10 fields, saw 12\n",
      "Skipping line 29906: expected 10 fields, saw 11\n",
      "Skipping line 31625: expected 10 fields, saw 11\n",
      "Skipping line 33020: expected 10 fields, saw 11\n",
      "Skipping line 35748: expected 10 fields, saw 11\n",
      "Skipping line 35962: expected 10 fields, saw 11\n",
      "Skipping line 37770: expected 10 fields, saw 11\n",
      "Skipping line 38105: expected 10 fields, saw 11\n",
      "Skipping line 38275: expected 10 fields, saw 11\n",
      "Skipping line 38404: expected 10 fields, saw 12\n",
      "\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   Accessories       0.99      0.98      0.99      2333\n",
      "       Apparel       0.99      1.00      0.99      4243\n",
      "      Footwear       0.99      0.99      0.99      1831\n",
      "    Free Items       0.00      0.00      0.00        19\n",
      " Personal Care       1.00      0.97      0.98       455\n",
      "Sporting Goods       0.00      0.00      0.00         4\n",
      "\n",
      "      accuracy                           0.99      8885\n",
      "     macro avg       0.66      0.66      0.66      8885\n",
      "  weighted avg       0.99      0.99      0.99      8885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot Recommendation: Carlton London Women Stylish Black Flats\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# File path to your CSV dataset\n",
    "file_path = r\"C:\\Users\\samee\\Downloads\\styles.csv\\styles.csv\"  # Update with your actual file path\n",
    "\n",
    "# Load your fashion dataset from CSV with error handling\n",
    "df = pd.read_csv(file_path, error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "# Example preprocessing (adjust based on your dataset structure)\n",
    "data = df['productDisplayName'].astype(str).tolist()  # Use product names for training\n",
    "labels = df['masterCategory'].astype(str).tolist()\n",
    "\n",
    "# Tokenization function using NLTK\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "data_vectors = vectorizer.fit_transform(data)\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification report (optional)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to process user query and provide recommendations\n",
    "def process_query(user_query):\n",
    "    query_vector = vectorizer.transform([user_query])\n",
    "    predicted_intent = clf.predict(query_vector)[0]\n",
    "    \n",
    "    # Filter data based on predicted_intent for recommendations\n",
    "    filtered_data = [item for item, label in zip(data, labels) if label == predicted_intent]\n",
    "    \n",
    "    # Use TF-IDF and cosine similarity for recommendation\n",
    "    data_vectors_filtered = vectorizer.transform(filtered_data)\n",
    "    similarities = cosine_similarity(query_vector, data_vectors_filtered)\n",
    "    \n",
    "    # Retrieve top recommendation\n",
    "    top_idx = similarities.argsort()[0][-1]\n",
    "    recommendation = filtered_data[top_idx]\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Looking for stylish Adidas shoes\"\n",
    "response = process_query(user_query)\n",
    "print(\"\\nChatbot Recommendation:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
